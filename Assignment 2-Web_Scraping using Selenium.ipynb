{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1) Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. \n",
    "    Scrape the job-title, job-location, company_name, experience_required of the first 10 jobs data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Driver\n",
    "driver = webdriver.Chrome(r'C:/Users/DELL/chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill = driver.find_element_by_id(\"qsb-keyword-sugg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element_by_id(\"qsb-location-sugg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "find=(driver.find_element_by_class_name(\"btn\")).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_profiles = []\n",
    "companies = []\n",
    "experiences = []\n",
    "salaries = []\n",
    "locations = []\n",
    "\n",
    "job_profile=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/a\")[0:10]\n",
    "\n",
    "company=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/div/a[1]\")[0:10]\n",
    "\n",
    "experience=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/ul/li[1]\")[0:10]\n",
    "\n",
    "salary = driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/ul/li[2]/span\")[0:10]\n",
    "\n",
    "location = driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/ul/li[3]/span\")[0:10]\n",
    "\n",
    "for job in job_profile:\n",
    "    job_profiles.append(job.text)\n",
    "for comp in company:\n",
    "    companies.append(comp.text)\n",
    "\n",
    "for exp in experience:\n",
    "    experiences.append(exp.text)\n",
    "    \n",
    "for sal in salary:\n",
    "    salaries.append(sal.text)\n",
    "    \n",
    "for loc in location:\n",
    "    locations.append(loc.text)\n",
    "    \n",
    "\n",
    "job_df=pd.DataFrame({'Job_Profile':job_profiles,\n",
    "                         'Company':companies,\n",
    "                         'Experience':experiences,\n",
    "                         'Salary':salaries,\n",
    "                         'Location':locations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Profile</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fresher Data Engineer / Data Scientist / Data ...</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>3,50,000 - 8,50,000 PA.</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAS AML Data Analyst / Trainee &amp; Data Science,...</td>\n",
       "      <td>MagicBase Royal BD Pvt Ltd</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>50,000 - 2,00,000 PA.</td>\n",
       "      <td>Bengaluru(Whitefield)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring Data Analysts</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>3,00,000 - 6,00,000 PA.</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring Data Analysts</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>2,50,000 - 5,50,000 PA.</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Study Data Analyst</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Cognizant Technology Solutions India Ltd</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Data Analyst | Reinsurance Domain</td>\n",
       "      <td>Mphasis Limited</td>\n",
       "      <td>10-15 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Job_Profile  \\\n",
       "0  Fresher Data Engineer / Data Scientist / Data ...   \n",
       "1                        Data Scientist/Data Analyst   \n",
       "2                              Business Data Analyst   \n",
       "3  SAS AML Data Analyst / Trainee & Data Science,...   \n",
       "4                               Hiring Data Analysts   \n",
       "5                               Hiring Data Analysts   \n",
       "6                                       Data Analyst   \n",
       "7                                 Study Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9         Business Data Analyst | Reinsurance Domain   \n",
       "\n",
       "                                             Company Experience  \\\n",
       "0                      ACHYUTAS SOFT PRIVATE LIMITED    0-2 Yrs   \n",
       "1  CAIA-Center For Artificial Intelligence & Adva...    0-3 Yrs   \n",
       "2                                             NetApp    2-3 Yrs   \n",
       "3                         MagicBase Royal BD Pvt Ltd    0-5 Yrs   \n",
       "4                  Flipkart Internet Private Limited    2-5 Yrs   \n",
       "5                  Flipkart Internet Private Limited    2-5 Yrs   \n",
       "6            GlaxoSmithKline Pharmaceuticals Limited    3-5 Yrs   \n",
       "7            GlaxoSmithKline Pharmaceuticals Limited    4-8 Yrs   \n",
       "8           Cognizant Technology Solutions India Ltd    3-4 Yrs   \n",
       "9                                    Mphasis Limited  10-15 Yrs   \n",
       "\n",
       "                    Salary                             Location  \n",
       "0  3,50,000 - 8,50,000 PA.      Delhi NCR, Bengaluru, Hyderabad  \n",
       "1  3,50,000 - 4,50,000 PA.  Chennai, Pune, Bengaluru, Hyderabad  \n",
       "2            Not disclosed                            Bengaluru  \n",
       "3    50,000 - 2,00,000 PA.                Bengaluru(Whitefield)  \n",
       "4  3,00,000 - 6,00,000 PA.                            Bengaluru  \n",
       "5  2,50,000 - 5,50,000 PA.                            Bengaluru  \n",
       "6            Not disclosed                     Bengaluru, India  \n",
       "7            Not disclosed                            Bengaluru  \n",
       "8            Not disclosed                            Bengaluru  \n",
       "9            Not disclosed                            Bengaluru  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. \n",
    "    You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "\n",
    "#Install Driver\n",
    "driver = webdriver.Chrome(r'C:/Users/DELL/chromedriver.exe')\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "skill = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "skill.send_keys(\"Data Scientist\")\n",
    "\n",
    "\n",
    "location = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "location.send_keys(\"Bangalore\")\n",
    "find=(driver.find_element_by_class_name(\"btn\")).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_profiles = []\n",
    "companies = []\n",
    "experiences = []\n",
    "salaries = []\n",
    "locations = []\n",
    "\n",
    "job_profile=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/a\")[0:10]\n",
    "\n",
    "company=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/div/a[1]\")[0:10]\n",
    "\n",
    "experience=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/ul/li[1]\")[0:10]\n",
    "\n",
    "salary = driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/ul/li[2]/span\")[0:10]\n",
    "\n",
    "location = driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/ul/li[3]/span\")[0:10]\n",
    "\n",
    "for job in job_profile:\n",
    "    job_profiles.append(job.text)\n",
    "    \n",
    "for comp in company:\n",
    "    companies.append(comp.text)\n",
    "\n",
    "for exp in experience:\n",
    "    experiences.append(exp.text)\n",
    "    \n",
    "for sal in salary:\n",
    "    salaries.append(sal.text)\n",
    "    \n",
    "for loc in location:\n",
    "    locations.append(loc.text)\n",
    "\n",
    "job_df=pd.DataFrame({'Job_Profile':job_profiles,\n",
    "                         'Company':companies,\n",
    "                         'Experience':experiences,\n",
    "                         'Salary':salaries,\n",
    "                         'Location':locations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Profile</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fresher Data Engineer / Data Scientist / Data ...</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>3,50,000 - 8,50,000 PA.</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Python/MATLAB/Machine Learnin...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/Data Mi...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Machine Learning/Data Mining</td>\n",
       "      <td>Minions Ventures</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist - NLP/ Python/ R</td>\n",
       "      <td>AVI Consulting LLP</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru, Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>7,00,000 - 15,00,000 PA.</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>7,00,000 - 15,00,000 PA.</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Artificial Intelligence Analyst/Data Scientist</td>\n",
       "      <td>TalentCo Search Pvt Ltd</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Mumbai, Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Job_Profile  \\\n",
       "0  Fresher Data Engineer / Data Scientist / Data ...   \n",
       "1                        Data Scientist/Data Analyst   \n",
       "2  Data Scientist - Python/MATLAB/Machine Learnin...   \n",
       "3  Lead Data Scientist - Machine Learning/Data Mi...   \n",
       "4      Data Scientist - Machine Learning/Data Mining   \n",
       "5             Senior Data Scientist - NLP/ Python/ R   \n",
       "6  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "7  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "8                  Data Scientist - Machine Learning   \n",
       "9     Artificial Intelligence Analyst/Data Scientist   \n",
       "\n",
       "                                             Company Experience  \\\n",
       "0                      ACHYUTAS SOFT PRIVATE LIMITED    0-2 Yrs   \n",
       "1  CAIA-Center For Artificial Intelligence & Adva...    0-3 Yrs   \n",
       "2                       Wrackle Technologies Pvt Ltd    3-8 Yrs   \n",
       "3                       Wrackle Technologies Pvt Ltd   6-11 Yrs   \n",
       "4                                   Minions Ventures    6-8 Yrs   \n",
       "5                                 AVI Consulting LLP    4-9 Yrs   \n",
       "6                                           CES Ltd.    2-7 Yrs   \n",
       "7                                           CES Ltd.    2-7 Yrs   \n",
       "8                  BLUE YONDER INDIA PRIVATE LIMITED    2-7 Yrs   \n",
       "9                            TalentCo Search Pvt Ltd    1-5 Yrs   \n",
       "\n",
       "                     Salary                                           Location  \n",
       "0   3,50,000 - 8,50,000 PA.                    Delhi NCR, Bengaluru, Hyderabad  \n",
       "1   3,50,000 - 4,50,000 PA.                Chennai, Pune, Bengaluru, Hyderabad  \n",
       "2             Not disclosed                                          Bengaluru  \n",
       "3             Not disclosed                                          Bengaluru  \n",
       "4             Not disclosed                                          Bengaluru  \n",
       "5             Not disclosed                               Bengaluru, Hyderabad  \n",
       "6  7,00,000 - 15,00,000 PA.  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...  \n",
       "7  7,00,000 - 15,00,000 PA.  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...  \n",
       "8             Not disclosed                                          Bengaluru  \n",
       "9             Not disclosed                                  Mumbai, Bengaluru  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Roles and Responsibilities', 'Analytical Skills:To work with large amounts of data: facts, figures, and number crunching.', 'This is your opportunity to join the disruptive startup for an exciting journey in Digital analytics and optimization services!', 'Develop database design, assessment and modelling to identify best approach for accessing various data sources for use in the overall reporting solution in a manner that is efficient and that supports the Banks Business agenda.', 'Must have strong work excel experience in V-Look up and all basic concepts in MS-Excel for data analysis 1.', 'Ability to search for the required data and all that is related to it.', 'Building and iterating reports (with eventual design collaboration) based around a large volume of data, from multiple teams - providing data results communicated in required formats and around production data to determine QA of data collected and completeness of data - supporting the data integrity and continued maintenance of data.', 'In this role, you will have an opportunity to work with vast amounts of meaningful data, made accessible through best-in-class analytical and Business Intelligence tools.', 'Desired Candidate Profile', 'Building medium to complex periodic reports and analytical dashboards using advanced excel skills.', 'Ability to work collaboratively with others but also autonomously as needed.', 'Be able to work under tight deadlines without compromising on quality.', '-Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.', 'Collate multiple data points and build up analysis to derive relevant market insights.', 'Good oral and written communication skills.', 'Strong interpersonal skills with the ability to work with a variety of individuals, both internal and external at a variety of. levels in the organization.', 'Job Benefits & Perks\\n2 Laks to 4 laks']\n"
     ]
    }
   ],
   "source": [
    "url='https://www.naukri.com/job-listings-fresher-data-engineer-data-scientist-data-analyst-requirements-achyutas-soft-private-limited-delhi-ncr-bengaluru-bangalore-hyderabad-secunderabad-0-to-2-years-061220001192?src=jobsearchDesk&sid=16081846081768416&xp=1&px=1'\n",
    "\n",
    "#Install Driver\n",
    "driver = webdriver.Chrome(r'C:/Users/DELL/chromedriver.exe')\n",
    "driver.get(url)\n",
    "\n",
    "job_descriptions = []\n",
    "job_description = driver.find_elements_by_xpath(\"//*[@id='root']/main/div[2]/div[2]/section[2]/div[1]/p\")\n",
    "for desc in job_description:\n",
    "    job_descriptions.append(desc.text)\n",
    "print(job_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3:In this question you have to scrape data using the filters available on the webpage 'naukri.com'\n",
    "\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "\n",
    "#Install Driver\n",
    "driver = webdriver.Chrome(r'C:/Users/DELL/chromedriver.exe')\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "skill = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "skill.send_keys(\"Data Scientist\")\n",
    "\n",
    "find=(driver.find_element_by_class_name(\"btn\")).click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_check_box = driver.find_element_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/i\").click()\n",
    "time.sleep(5)\n",
    "sal_check_box = driver.find_element_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[2]/label/i\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_profiles = []\n",
    "companies = []\n",
    "experiences = []\n",
    "salaries = []\n",
    "locations = []\n",
    "\n",
    "job_profile=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/a\")[0:10]\n",
    "\n",
    "company=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/div/a[1]\")[0:10]\n",
    "\n",
    "experience=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/ul/li[1]\")[0:10]\n",
    "\n",
    "salary = driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/ul/li[2]/span\")[0:10]\n",
    "\n",
    "location = driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/ul/li[3]/span\")[0:10]\n",
    "\n",
    "for job in job_profile:\n",
    "    job_profiles.append(job.text)\n",
    "    \n",
    "for comp in company:\n",
    "    companies.append(comp.text)\n",
    "\n",
    "for exp in experience:\n",
    "    experiences.append(exp.text)\n",
    "    \n",
    "for sal in salary:\n",
    "    salaries.append(sal.text)\n",
    "    \n",
    "for loc in location:\n",
    "    locations.append(loc.text)\n",
    "\n",
    "job_df=pd.DataFrame({'Job_Profile':job_profiles,\n",
    "                         'Company':companies,\n",
    "                         'Experience':experiences,\n",
    "                         'Salary':salaries,\n",
    "                         'Location':locations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Profile</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fresher Data Engineer / Data Scientist / Data ...</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>3,50,000 - 8,50,000 PA.</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Python/Machine Learning</td>\n",
       "      <td>Jubna</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>PureSoftware Pvt Ltd.</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Delhi NCR, Noida(Sector-142 Noida)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Excellent opportunity For Lead Data Scientist ...</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Delhi NCR(Sector-142 Noida), Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Delhi NCR, Noida(Sector-142 Noida)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Excellent opportunity For Lead Data Scientist ...</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Delhi NCR(Sector-142 Noida), Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Stark Industries</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Job | Opportunity For Senior Role(Data Scienti...</td>\n",
       "      <td>BA Continuum India Pvt. Ltd</td>\n",
       "      <td>14-17 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Gandhinagar, Delhi NCR, Mumbai, Gurgaon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Job_Profile  \\\n",
       "0  Fresher Data Engineer / Data Scientist / Data ...   \n",
       "1           Data Scientist - Python/Machine Learning   \n",
       "2                                     Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4                                Lead Data Scientist   \n",
       "5  Excellent opportunity For Lead Data Scientist ...   \n",
       "6                                Lead Data Scientist   \n",
       "7  Excellent opportunity For Lead Data Scientist ...   \n",
       "8                                     Data Scientist   \n",
       "9  Job | Opportunity For Senior Role(Data Scienti...   \n",
       "\n",
       "                             Company Experience                   Salary  \\\n",
       "0      ACHYUTAS SOFT PRIVATE LIMITED    0-2 Yrs  3,50,000 - 8,50,000 PA.   \n",
       "1                              Jubna    5-8 Yrs            Not disclosed   \n",
       "2              PureSoftware Pvt Ltd.    5-9 Yrs            Not disclosed   \n",
       "3              World Wide Technology    3-8 Yrs            Not disclosed   \n",
       "4  NEC CORPORATION INDIA PRIVATE LTD   9-14 Yrs            Not disclosed   \n",
       "5  NEC CORPORATION INDIA PRIVATE LTD   9-14 Yrs            Not disclosed   \n",
       "6  NEC CORPORATION INDIA PRIVATE LTD   9-14 Yrs            Not disclosed   \n",
       "7  NEC CORPORATION INDIA PRIVATE LTD   9-14 Yrs            Not disclosed   \n",
       "8                   Stark Industries    3-5 Yrs            Not disclosed   \n",
       "9        BA Continuum India Pvt. Ltd  14-17 Yrs            Not disclosed   \n",
       "\n",
       "                                  Location  \n",
       "0          Delhi NCR, Bengaluru, Hyderabad  \n",
       "1                                    Noida  \n",
       "2                                  Gurgaon  \n",
       "3                                  Gurgaon  \n",
       "4       Delhi NCR, Noida(Sector-142 Noida)  \n",
       "5       Delhi NCR(Sector-142 Noida), Noida  \n",
       "6       Delhi NCR, Noida(Sector-142 Noida)  \n",
       "7       Delhi NCR(Sector-142 Noida), Noida  \n",
       "8                                    Delhi  \n",
       "9  Gandhinagar, Delhi NCR, Mumbai, Gurgaon  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.glassdoor.co.in/index.htm'\n",
    "\n",
    "#Install Driver\n",
    "driver = webdriver.Chrome(r'C:/Users/DELL/chromedriver.exe')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill = driver.find_element_by_xpath(\"//*[@id='sc.keyword']\")\n",
    "skill.send_keys(\"Data Scientist\")\n",
    "\n",
    "location = driver.find_element_by_xpath(\"//*[@id='sc.location']\")\n",
    "location.send_keys(\"Noida\")\n",
    "\n",
    "find=(driver.find_element_by_xpath(\"//*[@id='scBar']/div/button/span\")).click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = []\n",
    "ratings = []\n",
    "posted_time = []\n",
    "locations = []\n",
    "\n",
    "company=driver.find_elements_by_xpath(\"//*[@id='MainCol']/div[1]/ul/li/div[2]/div[1]/a/span\")[0:10]\n",
    "\n",
    "rating=driver.find_elements_by_xpath(\"//*[@id='MainCol']/div[1]/ul/li/div[1]/span\")[0:10]\n",
    "\n",
    "posted = driver.find_elements_by_xpath(\"//*[@id='MainCol']/div[1]/ul/li/div[2]/div[3]/div[2]/div[2]\")[0:10]\n",
    "    \n",
    "for comp in company:\n",
    "    companies.append(comp.text)\n",
    "\n",
    "for rate in rating:\n",
    "    ratings.append(rate.text)\n",
    "    \n",
    "for post in posted:\n",
    "    posted_time.append(post.text)\n",
    "\n",
    "job_df=pd.DataFrame({'Company':companies,\n",
    "                     'Ratings':ratings,\n",
    "                     'Posted On':posted_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Posted On</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>3.8</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IHS Markit</td>\n",
       "      <td>4.1</td>\n",
       "      <td>8d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GroundTruth</td>\n",
       "      <td>3.3</td>\n",
       "      <td>21d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MARKTECH CONSULTANCY</td>\n",
       "      <td>5</td>\n",
       "      <td>5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gauge Data Solutions</td>\n",
       "      <td>3.7</td>\n",
       "      <td>27d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Algoscale</td>\n",
       "      <td>3.7</td>\n",
       "      <td>27d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SearchUrCollege</td>\n",
       "      <td>4</td>\n",
       "      <td>27d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>4.1</td>\n",
       "      <td>8d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Priority Vendor</td>\n",
       "      <td>3.7</td>\n",
       "      <td>27d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Ratings Posted On\n",
       "0               Genpact     3.8       24h\n",
       "1            IHS Markit     4.1        8d\n",
       "2           GroundTruth     3.3       21d\n",
       "3  MARKTECH CONSULTANCY       5        5d\n",
       "4              Techlive     3.1        6d\n",
       "5  Gauge Data Solutions     3.7       27d\n",
       "6             Algoscale     3.7       27d\n",
       "7       SearchUrCollege       4       27d\n",
       "8        Biz2Credit Inc     4.1        8d\n",
       "9       Priority Vendor     3.7       27d"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the page.\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "6. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.glassdoor.co.in/Salaries/index.htm'\n",
    "\n",
    "#Install Driver\n",
    "driver = webdriver.Chrome(r'C:/Users/DELL/chromedriver.exe')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill = driver.find_element_by_name(\"sc.keyword\")\n",
    "skill.send_keys(\"Data Scientist\")\n",
    "\n",
    "location = driver.find_element_by_xpath('//*[@id=\"LocationSearch\"]')\n",
    "location.clear()\n",
    "location.send_keys(\"Noida\")\n",
    "\n",
    "find=(driver.find_element_by_class_name(\"gd-btn-mkt\")).click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = []\n",
    "min_sal = []\n",
    "max_sal = []\n",
    "avg_sal = []\n",
    "\n",
    "company=driver.find_elements_by_xpath(\"//*[@id='SalariesByCompany']/div[1]/div/div/div[1]/div/div[2]/p[2]\")[0:10]\n",
    "\n",
    "minimum = driver.find_elements_by_xpath(\"//*[@id='SalariesByCompany']/div[1]/div/div/div[3]/div/div[2]/span[1]\")[0:10]\n",
    "\n",
    "maximum = driver.find_elements_by_xpath(\"//*[@id='SalariesByCompany']/div[1]/div/div/div[3]/div/div[2]/span[2]\")[0:10]\n",
    "\n",
    "average = driver.find_elements_by_xpath(\"//*[@id='SalariesByCompany']/div[1]/div/div/div[2]/strong\")[0:10]\n",
    "    \n",
    "for comp in company:\n",
    "    companies.append(comp.text)\n",
    "\n",
    "for sal in minimum:\n",
    "    min_sal.append(sal.text)\n",
    "    \n",
    "for sal in maximum:\n",
    "    max_sal.append(sal.text)\n",
    "    \n",
    "for sal in average:\n",
    "    avg_sal.append(sal.text)\n",
    "\n",
    "job_df=pd.DataFrame({'Company':companies,\n",
    "                     'min_sal':min_sal,\n",
    "                     'max_sal':max_sal,\n",
    "                     'avg_sal' :avg_sal})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>min_sal</th>\n",
       "      <th>max_sal</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹705K</td>\n",
       "      <td>₹11,495K</td>\n",
       "      <td>₹ 12,83,026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹571K</td>\n",
       "      <td>₹2,200K</td>\n",
       "      <td>₹ 11,19,272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹580K</td>\n",
       "      <td>₹2,700K</td>\n",
       "      <td>₹ 7,52,445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹468K</td>\n",
       "      <td>₹1,595K</td>\n",
       "      <td>₹ 8,28,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹708K</td>\n",
       "      <td>₹1,557K</td>\n",
       "      <td>₹ 13,21,601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analytics Vidhya</td>\n",
       "      <td>₹14K</td>\n",
       "      <td>₹22K</td>\n",
       "      <td>₹ 20,889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹488K</td>\n",
       "      <td>₹1,000K</td>\n",
       "      <td>₹ 6,33,432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>₹784K</td>\n",
       "      <td>₹1,250K</td>\n",
       "      <td>₹ 9,96,446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹496K</td>\n",
       "      <td>₹1,138K</td>\n",
       "      <td>₹ 7,71,320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vidooly Media Tech</td>\n",
       "      <td>₹8K</td>\n",
       "      <td>₹20K</td>\n",
       "      <td>₹ 12,669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Company min_sal   max_sal      avg_sal\n",
       "0                       Delhivery   ₹705K  ₹11,495K  ₹ 12,83,026\n",
       "1                       Accenture   ₹571K   ₹2,200K  ₹ 11,19,272\n",
       "2                             IBM   ₹580K   ₹2,700K   ₹ 7,52,445\n",
       "3              Ericsson-Worldwide   ₹468K   ₹1,595K   ₹ 8,28,000\n",
       "4              UnitedHealth Group   ₹708K   ₹1,557K  ₹ 13,21,601\n",
       "5                Analytics Vidhya    ₹14K      ₹22K     ₹ 20,889\n",
       "6       Tata Consultancy Services   ₹488K   ₹1,000K   ₹ 6,33,432\n",
       "7  Cognizant Technology Solutions   ₹784K   ₹1,250K   ₹ 9,96,446\n",
       "8              Valiance Solutions   ₹496K   ₹1,138K   ₹ 7,71,320\n",
       "9              Vidooly Media Tech     ₹8K      ₹20K     ₹ 12,669"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/'\n",
    "\n",
    "#Install Driver\n",
    "driver = webdriver.Chrome(r'C:/Users/DELL/chromedriver.exe')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = driver.find_element_by_xpath(\"//*[@id='container']/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys(\"sunglasses\")\n",
    "product.send_keys(Keys.RETURN)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brands = []\n",
    "Product_Descriptions = []\n",
    "Prices = []\n",
    "Discounts = []\n",
    "start_page = 1\n",
    "end_page = 5\n",
    "\n",
    "for page in range(start_page,end_page):\n",
    "\n",
    "    Brand = driver.find_elements_by_xpath(\"//*[@id='container']/div/div[3]/div[2]/div[1]/div[2]/div/div/div/div/div/div[1]\")\n",
    "\n",
    "    Product_Description = driver.find_elements_by_xpath(\"//*[@id='container']/div/div[3]/div[2]/div[1]/div[2]/div/div/div/div/div/a[1]\")[2:]\n",
    "\n",
    "    Price = driver.find_elements_by_xpath(\"//*[@id='container']/div/div[3]/div[2]/div[1]/div[2]/div/div/div/div/div/a[2]/div/div[1]\")\n",
    "\n",
    "    Discount = driver.find_elements_by_xpath(\"//*[@id='container']/div/div[3]/div[2]/div[1]/div[2]/div/div/div/div/div/a[2]/div/div[3]/span\")\n",
    "\n",
    "    for i in Brand:\n",
    "        Brands.append(i.text)\n",
    "\n",
    "    for i in Product_Description:\n",
    "        Product_Descriptions.append(i.text)\n",
    "\n",
    "    for i in Price:\n",
    "        Prices.append(i.text)\n",
    "\n",
    "    for i in Discount:\n",
    "        Discounts.append(i.text)\n",
    "        \n",
    "    next_btn = driver.find_element_by_xpath(\"//*[@id='container']/div/div[3]/div[2]/div[1]/div[2]/div[12]/div/div/nav/a/span\")\n",
    "    if next_btn.text=='Next':\n",
    "            next_btn.click()\n",
    "            time.sleep(5)\n",
    "\n",
    "    product_details=pd.DataFrame({'Brands':Brands,\n",
    "                         'Product Descriptions':Product_Descriptions,\n",
    "                         'Prices':Prices,\n",
    "                         'Discounts' :Discounts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brands</th>\n",
       "      <th>Product Descriptions</th>\n",
       "      <th>Prices</th>\n",
       "      <th>Discounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JUST STYLE</td>\n",
       "      <td>UV Protection Round Sunglasses (48)</td>\n",
       "      <td>₹125</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Retro Squar...</td>\n",
       "      <td>₹500</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹1,116</td>\n",
       "      <td>14% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Specsmakers</td>\n",
       "      <td>Polarized Aviator Sunglasses (54)</td>\n",
       "      <td>₹696</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fravy</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹269</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>INSH</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Re...</td>\n",
       "      <td>₹345</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>HAMIW COLLECTION</td>\n",
       "      <td>UV Protection Round, Oval, Spectacle , Clubmas...</td>\n",
       "      <td>₹164</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Billion</td>\n",
       "      <td>Riding Glasses Spectacle Sunglasses (Free Size)</td>\n",
       "      <td>₹287</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Phenomenal</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>₹269</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection Wrap-around, Rectangular Sunglas...</td>\n",
       "      <td>₹1,367</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brands                               Product Descriptions  \\\n",
       "0          JUST STYLE                UV Protection Round Sunglasses (48)   \n",
       "1              Aislin  UV Protection, Gradient Butterfly, Retro Squar...   \n",
       "2            Fastrack              UV Protection Aviator Sunglasses (58)   \n",
       "3         Specsmakers                  Polarized Aviator Sunglasses (54)   \n",
       "4               Fravy  UV Protection Retro Square Sunglasses (Free Size)   \n",
       "..                ...                                                ...   \n",
       "155              INSH  UV Protection, Night Vision, Riding Glasses Re...   \n",
       "156  HAMIW COLLECTION  UV Protection Round, Oval, Spectacle , Clubmas...   \n",
       "157           Billion    Riding Glasses Spectacle Sunglasses (Free Size)   \n",
       "158        Phenomenal  Polarized, UV Protection Retro Square Sunglass...   \n",
       "159            Aislin  UV Protection Wrap-around, Rectangular Sunglas...   \n",
       "\n",
       "     Prices Discounts  \n",
       "0      ₹125   58% off  \n",
       "1      ₹500   67% off  \n",
       "2    ₹1,116   14% off  \n",
       "3      ₹696   65% off  \n",
       "4      ₹269   82% off  \n",
       "..      ...       ...  \n",
       "155    ₹345   86% off  \n",
       "156    ₹164   83% off  \n",
       "157    ₹287   88% off  \n",
       "158    ₹269   73% off  \n",
       "159  ₹1,367   67% off  \n",
       "\n",
       "[160 rows x 4 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach scrape:\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "Scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace'\n",
    "\n",
    "#Install Driver\n",
    "driver = webdriver.Chrome(r'C:/Users/DELL/chromedriver.exe')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_revies = driver.find_element_by_xpath(\"//*[@id='container']/div/div[3]/div[1]/div[2]/div[10]/div/div/div[5]/div/a/div/span\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings = []\n",
    "Review_summaries = []\n",
    "Full_Reviews = []\n",
    "start = 1\n",
    "end = 12\n",
    "\n",
    "for page in range(start,end+1):\n",
    "\n",
    "    Rating = driver.find_elements_by_xpath(\"//*[@id='container']/div/div[3]/div/div[1]/div[2]/div/div/div/div/div[1]/div\")[2:]\n",
    "\n",
    "    Review_summary = driver.find_elements_by_xpath(\"//*[@id='container']/div/div[3]/div/div[1]/div[2]/div/div/div/div/div[1]/p\")\n",
    "\n",
    "    Full_Review = driver.find_elements_by_xpath(\"//*[@id='container']/div/div[3]/div/div[1]/div[2]/div/div/div/div/div[2]/div/div/div\")\n",
    "\n",
    "    for i in Rating:\n",
    "        Ratings.append(i.text)\n",
    "\n",
    "    for i in Review_summary:\n",
    "        Review_summaries.append(i.text)\n",
    "\n",
    "    for i in Full_Review:\n",
    "        Full_Reviews.append(i.text)\n",
    "        \n",
    "    next_btn = driver.find_element_by_xpath(\"//*[@id='container']/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]/span\")\n",
    "\n",
    "    if next_btn.text =='Next':\n",
    "        next_btn.click()\n",
    "        time.sleep(5)\n",
    "\n",
    "    product_reviews=pd.DataFrame({'Ratings':Ratings,\n",
    "                         'Review Summary':Review_summaries,\n",
    "                         'Full Reviews':Full_Reviews})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Upgraded from iPhone SE. The device is bulky. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Great phone with great performance and no heat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>I Phone 11 is an amazing phone in a great pric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Best phone in this price segment people say th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>I have been using Iphone 11 for a week, the ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>3</td>\n",
       "      <td>Just okay</td>\n",
       "      <td>iPhone 11 is not better than Samsung s20 at th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>The best phone ever iphones no one can match a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Switched from iPhone X to iPhone 11 128 GB Ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Feels great to get back to iPhones after a gap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>4</td>\n",
       "      <td>Delightful</td>\n",
       "      <td>Everything is good in this phone. Not good for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ratings         Review Summary  \\\n",
       "0         5  Mind-blowing purchase   \n",
       "1         5              Fabulous!   \n",
       "2         5              Fabulous!   \n",
       "3         5              Fabulous!   \n",
       "4         5      Worth every penny   \n",
       "..      ...                    ...   \n",
       "115       3              Just okay   \n",
       "116       5                Awesome   \n",
       "117       5  Mind-blowing purchase   \n",
       "118       5         Simply awesome   \n",
       "119       4             Delightful   \n",
       "\n",
       "                                          Full Reviews  \n",
       "0    Upgraded from iPhone SE. The device is bulky. ...  \n",
       "1    Great phone with great performance and no heat...  \n",
       "2    I Phone 11 is an amazing phone in a great pric...  \n",
       "3    Best phone in this price segment people say th...  \n",
       "4    I have been using Iphone 11 for a week, the ba...  \n",
       "..                                                 ...  \n",
       "115  iPhone 11 is not better than Samsung s20 at th...  \n",
       "116  The best phone ever iphones no one can match a...  \n",
       "117  Switched from iPhone X to iPhone 11 128 GB Ver...  \n",
       "118  Feels great to get back to iPhones after a gap...  \n",
       "119  Everything is good in this phone. Not good for...  \n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/'\n",
    "\n",
    "#Install Driver\n",
    "driver = webdriver.Chrome(r'C:/Users/DELL/chromedriver.exe')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = driver.find_element_by_xpath(\"//*[@id='container']/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys(\"sneakers\")\n",
    "product.send_keys(Keys.RETURN)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brands = []\n",
    "Product_Descriptions = []\n",
    "Prices = []\n",
    "Discounts = []\n",
    "start_page = 1\n",
    "end_page = 5\n",
    "\n",
    "for page in range(start_page,end_page):\n",
    "\n",
    "    Brand = driver.find_elements_by_xpath(\"//*[@id='container']/div/div[3]/div[2]/div[1]/div[2]/div/div/div/div/div/div[1]\")\n",
    "\n",
    "    Product_Description = driver.find_elements_by_xpath(\"//*[@id='container']/div/div[3]/div[2]/div[1]/div[2]/div/div/div/div/div/a[1]\")[4:]\n",
    "\n",
    "    Price = driver.find_elements_by_xpath(\"//*[@id='container']/div/div[3]/div[2]/div[1]/div[2]/div/div/div/div/div/a[2]/div/div[1]\")\n",
    "\n",
    "    Discount = driver.find_elements_by_xpath(\"//*[@id='container']/div/div[3]/div[2]/div[1]/div[2]/div/div/div/div/div/a[2]/div/div[3]/span\")\n",
    "\n",
    "    for i in Brand:\n",
    "        Brands.append(i.text)\n",
    "        #print(Brands)\n",
    "\n",
    "    for i in Product_Description:\n",
    "        Product_Descriptions.append(i.text)\n",
    "        #print(Product_Descriptions)\n",
    "\n",
    "    for i in Price:\n",
    "        Prices.append(i.text)\n",
    "        #print(Prices)\n",
    "\n",
    "    for i in Discount:\n",
    "        Discounts.append(i.text)\n",
    "        #print(Discounts)\n",
    "        \n",
    "    next_btn = driver.find_element_by_xpath(\"//*[@id='container']/div/div[3]/div[2]/div[1]/div[2]/div[12]/div/div/nav/a/span\")\n",
    "    if next_btn.text=='Next':\n",
    "            next_btn.click()\n",
    "            time.sleep(5)\n",
    "\n",
    "    product_details=pd.DataFrame({'Brands':Brands,\n",
    "                         'Product Descriptions':Product_Descriptions,\n",
    "                         'Prices':Prices,\n",
    "                         'Discounts' :Discounts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brands</th>\n",
       "      <th>Product Descriptions</th>\n",
       "      <th>Prices</th>\n",
       "      <th>Discounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Easy Vulc 2.0 Sneakers For Men</td>\n",
       "      <td>₹1,595</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bonexy</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bonexy</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WHITE WALKERS</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wen Hawk</td>\n",
       "      <td>Latest Stylish Casual sneakers for men | Lace ...</td>\n",
       "      <td>₹358</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Kizaar</td>\n",
       "      <td>Fashionable Casual, Canvas,official or Partywe...</td>\n",
       "      <td>₹491</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Shoefly</td>\n",
       "      <td>Combo Men Pack of 2 Loafers Shoes Sneakers For...</td>\n",
       "      <td>₹367</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>revord</td>\n",
       "      <td>Sneakers For Men (BLACK) Sneakers For Men</td>\n",
       "      <td>₹199</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Smart Casuals Canvas Shoes Combo pack of 2 Sne...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>REFOAM</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹699</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brands                               Product Descriptions  Prices  \\\n",
       "0           ADIDAS                     Easy Vulc 2.0 Sneakers For Men  ₹1,595   \n",
       "1           Bonexy                                   Sneakers For Men    ₹499   \n",
       "2           Bonexy                                   Sneakers For Men    ₹499   \n",
       "3    WHITE WALKERS                                   Sneakers For Men    ₹499   \n",
       "4         Wen Hawk  Latest Stylish Casual sneakers for men | Lace ...    ₹358   \n",
       "..             ...                                                ...     ...   \n",
       "155         Kizaar  Fashionable Casual, Canvas,official or Partywe...    ₹491   \n",
       "156        Shoefly  Combo Men Pack of 2 Loafers Shoes Sneakers For...    ₹367   \n",
       "157         revord          Sneakers For Men (BLACK) Sneakers For Men    ₹199   \n",
       "158         Chevit  Smart Casuals Canvas Shoes Combo pack of 2 Sne...    ₹379   \n",
       "159         REFOAM                                   Sneakers For Men    ₹699   \n",
       "\n",
       "    Discounts  \n",
       "0     58% off  \n",
       "1     50% off  \n",
       "2     50% off  \n",
       "3     50% off  \n",
       "4     64% off  \n",
       "..        ...  \n",
       "155   50% off  \n",
       "156   63% off  \n",
       "157   60% off  \n",
       "158   62% off  \n",
       "159   65% off  \n",
       "\n",
       "[160 rows x 4 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.myntra.com/shoes'\n",
    "\n",
    "#Install Driver\n",
    "driver = webdriver.Chrome(r'C:/Users/DELL/chromedriver.exe')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_check_box = driver.find_element_by_xpath(\"//*[@id='mountRoot']/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\").click()\n",
    "time.sleep(5)\n",
    "colour_check_box = driver.find_element_by_xpath(\"//*[@id='mountRoot']/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brands = []\n",
    "Product_Descriptions = []\n",
    "Prices = []\n",
    "start_page = 1\n",
    "end_page = 3\n",
    "\n",
    "for page in range(start_page,end_page):\n",
    "\n",
    "    Brand = driver.find_elements_by_xpath(\"//*[@id='desktopSearchResults']/div[2]/section/ul/li/a/div[2]/h3\")\n",
    "\n",
    "    Product_Description = driver.find_elements_by_xpath(\"//*[@id='desktopSearchResults']/div[2]/section/ul/li/a/div[2]/h4[1]\")\n",
    "\n",
    "    Price = driver.find_elements_by_xpath(\"//*[@id='desktopSearchResults']/div[2]/section/ul/li/a/div[2]/div/span[1]\")\n",
    "\n",
    "    for i in Brand:\n",
    "        Brands.append(i.text)\n",
    "        #print(Brands)\n",
    "\n",
    "    for i in Product_Description:\n",
    "        Product_Descriptions.append(i.text)\n",
    "        #print(Product_Descriptions)\n",
    "\n",
    "    for i in Price:\n",
    "        split = i.text.split('Rs. ')\n",
    "        #print(split)\n",
    "        split=split[1:2]\n",
    "        #print(split)\n",
    "        Prices.append(split)\n",
    "        #print(Prices)\n",
    "        \n",
    "    next_btn = driver.find_element_by_xpath(\"//*[@id='desktopSearchResults']/div[2]/section/div[2]/ul/li[12]\")\n",
    "    if next_btn.text=='Next':\n",
    "            next_btn.click()\n",
    "            time.sleep(5)\n",
    "\n",
    "    product_details=pd.DataFrame({'Brands':Brands,\n",
    "                         'Product Descriptions':Product_Descriptions,\n",
    "                         'Prices':Prices})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brands</th>\n",
       "      <th>Product Descriptions</th>\n",
       "      <th>Prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>AIR ZOOM PEGASUS Running Shoes</td>\n",
       "      <td>[11495]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Formal Slip-Ons</td>\n",
       "      <td>[14990]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Sneakers</td>\n",
       "      <td>[8999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men Lightweight Brogues</td>\n",
       "      <td>[7999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men HOVR STRT Sportstyle Shoes</td>\n",
       "      <td>[9999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Women Sneakers</td>\n",
       "      <td>[8999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Vanilla Moon</td>\n",
       "      <td>Women Solid Flat Boots</td>\n",
       "      <td>[8990]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Vanilla Moon</td>\n",
       "      <td>Women Solid Flat Boots</td>\n",
       "      <td>[8990]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Vanilla Moon</td>\n",
       "      <td>Women Solid Flat Boots</td>\n",
       "      <td>[8990]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Solid Leather Formal Penny Loafers</td>\n",
       "      <td>[8792]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Brands                    Product Descriptions   Prices\n",
       "0                   Nike          AIR ZOOM PEGASUS Running Shoes  [11495]\n",
       "1                   Geox             Men Leather Formal Slip-Ons  [14990]\n",
       "2                   Puma                         Unisex Sneakers   [8999]\n",
       "3              Cole Haan                 Men Lightweight Brogues   [7999]\n",
       "4           UNDER ARMOUR          Men HOVR STRT Sportstyle Shoes   [9999]\n",
       "..                   ...                                     ...      ...\n",
       "95                  FILA                          Women Sneakers   [8999]\n",
       "96          Vanilla Moon                  Women Solid Flat Boots   [8990]\n",
       "97          Vanilla Moon                  Women Solid Flat Boots   [8990]\n",
       "98          Vanilla Moon                  Women Solid Flat Boots   [8990]\n",
       "99  Heel & Buckle London  Men Solid Leather Formal Penny Loafers   [8792]\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
